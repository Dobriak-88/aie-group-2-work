# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target`, классы: 1 и 0, рапределение: 26% и 74% от общего количества
- Признаки: числовые

## 2. Protocol

- Разбиение: 0.25
- Подбор: 3 фолда, оптимизировали ROC-AUC
- Метрики: accuracy, F1, ROC-AUC (метрики уместны т.к. мы используем их для оценки модели для классификации)

## 3. Models

## DummyClassifier (базовый бейзлайн)
**Стратегия**: `strategy="most_frequent"` - всегда предсказывает наиболее частый класс

**Назначение**: Базовый уровень для сравнения, ниже которого не должна опускаться любая осмысленная модель

**Ключевой параметр**: `random_state=RANDOM_STATE` для воспроизводимости

## LogisticRegression (линейная модель)
**Пайплайн**: `StandardScaler()` + `LogisticRegression`

**Гиперпараметры**:
- `max_iter=1000` - максимальное число итераций оптимизации
- `C=1.0` - обратная сила регуляризации (по умолчанию)
- `random_state=RANDOM_STATE` - для воспроизводимости

**Назначение**: Линейная базовая модель для сравнения с более сложными алгоритмами

## DecisionTreeClassifier (дерево решений)
**Первоначальная модель**:
- `max_depth=10` - ограничение глубины дерева
- `min_samples_leaf=10` - минимальное количество образцов в листе
- `random_state=RANDOM_STATE`

**GridSearchCV для подбора гиперпараметров**:
- `max_depth`: [None, 3, 5, 8]
  - None - неограниченная глубина
  - Ограниченные значения для контроля переобучения
- `min_samples_leaf`: [1, 5, 10, 20]
  - Минимальное число образцов в листе
  - Большие значения упрощают дерево
- `ccp_alpha`: [0.0, 0.001, 0.005, 0.01]
  - Параметр cost-complexity pruning
  - Регуляризация через обрезку дерева

## RandomForestClassifier (случайный лес)
**Первоначальная модель**:
- `n_estimators=400` - количество деревьев в ансамбле
- `max_depth=10` (позже оптимизировано до 18)
- `oob_score=True` - оценка out-of-bag
- `n_jobs=-1` - параллельные вычисления
- `random_state=RANDOM_STATE`

**Эксперимент с max_depth**:
- Тестировались значения: от 5 до 20
- Наилучший результат: `max_depth=18`

**GridSearchCV для подбора гиперпараметров**:
- `max_depth`: [None, 6, 18]
  - None - неограниченная глубина
  - 6 и 18 - найденные оптимальные значения
- `min_samples_leaf`: [1, 5, 10]
  - Контроль размера листьев
- `max_features`: ["sqrt", 0.5]
  - "sqrt" - √n_features (по умолчанию для классификации)
  - 0.5 - 50% признаков

## GradientBoostingClassifier (градиентный бустинг)
**Первоначальная модель**:
- `n_estimators=300` - количество boosting-итераций
- `learning_rate=0.05` - темп обучения
- `max_depth=2` - глубина каждого дерева
- `random_state=RANDOM_STATE`

**GridSearchCV для подбора гиперпараметров**:
- `learning_rate`: [0.03, 0.05, 0.1]
  - Темп обучения (shrinkage)
  - Меньшие значения требуют больше деревьев
- `max_depth`: [2, 3, None]
  - Глубина деревьев-слабых учеников
  - 2-3 обычно оптимально для бустинга
- `max_leaf_nodes`: [15, 31, 63]
  - Альтернативный способ контроля сложности дерева
  - Ограничивает максимальное число листьев

## 4. Results

| Модель | Accuracy | F1-score | ROC-AUC |
|--------|----------|----------|---------|
| GradientBoosting | 0.910667 | 0.813023 | 0.932650 |
| RandomForest | 0.894000 | 0.763510 | 0.929797 |
| DecisionTree | 0.818667 | 0.619048 | 0.831701 |


Победитель: GradientBoosting по параметру ROC-AUC

## 5. Analysis

Изменение `random_state` для RandomForestClassifier является важным гиперпараметром, т.к. его изменение сильно влияет на итоговую точность модели.

```
Confusion Matrix (GradientBoosting):
[[2032   68]
 [ 104  196]]
 ```

### Вывод: 
Модель имеет точность 91%, но дисбаланс между precision (74%) и recall (65%). Лучше избегает ложных срабатываний, но пропускает 35% положительных случаев.



## 6. Conclusion

### Про деревья и ансамбли:

1. **Деревья** - простые интерпретируемые модели, но склонны к переобучению, требуют ограничений (max_depth, min_samples_leaf)

2. **Случайный лес** - ансамбль независимых деревьев, стабильнее одиночного дерева, дает оценку качества через OOB-score

3. **Градиентный бустинг** - последовательное улучшение ошибок, обычно показывает лучшие результаты, но требует тщательного подбора гиперпараметров (learning_rate, n_estimators)

4. **Ансамбли** превосходят одиночные модели в задачах классификации, особенно при наличии шума в данных

### Про честный ML-протокол:

1. **Baseline обязателен** - DummyClassifier показывает минимальный уровень, ниже которого нельзя опускаться

2. **Строгая валидация** - разделение на train/test с сохранением распределения классов (stratify), кросс-валидация для подбора гиперпараметров

3. **Единая оценка** - все модели сравниваются на одном тестовом наборе с одинаковыми метриками

4. **Воспроизводимость** - фиксированный random_state позволяет повторять эксперименты